{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The following notebook provides script of scraping the data <b>ijob.am.</b>\n",
    "The general sequence of steps I followed are:\n",
    "    \n",
    "1. [Dealing with infinite load button (\"Load more\") and getting all job urls](#load)\n",
    "2. [Defining a function getting data of interest from job announcements](#func)  \n",
    "3. [Crawling, getting and saving the data into csv](#crawl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2>1.Dealing with infinite load button (\"Load more\") and getting all job urls</h2> <a name=\"load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening browser\n",
    "browser=webdriver.Chrome()\n",
    "url_p=\"http://ijob.am/job-list/\"\n",
    "browser.get(url_p)\n",
    "browser.implicitly_wait(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: element not interactable\n",
      "  (Session info: chrome=77.0.3865.90)\n",
      "\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#dealing with \"Load more\" button: clicking it untill page is not refreshed\n",
    "while True:\n",
    "    try:\n",
    "        loadMoreButton = browser.find_element_by_class_name(\"load_more_jobs\")\n",
    "        time.sleep(2)\n",
    "        loadMoreButton.click()\n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "print(\"Complete\")\n",
    "page=browser.page_source\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing the page into html and saving in bs4\n",
    "page = BeautifulSoup(page,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all job urls\n",
    "job_desc_urls=[i.get(\"href\") for i in page.find_all(\"a\", class_= \"job_listing-clickbox\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2>2.Defining a function getting data of interest from job announcements</h2> <a name=\"func\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the selected data out of job announcement\n",
    "def get_all(url):\n",
    "    '''function sending request to job announcement pages and returning the outlined details'''\n",
    "    response=requests.get(url)\n",
    "    time.sleep(2)\n",
    "    page=response.text\n",
    "    page=BeautifulSoup(page, \"html.parser\")\n",
    "    company_name=page.find(\"li\", class_=\"job-company\").get_text()\n",
    "    position=page.find(\"h1\", class_=\"page-title\").get_text()\n",
    "    location=page.find(\"div\", class_=\"job-location\").get_text()\n",
    "    category=page.find(\"div\", class_=\"job_listing-categories\").get_text()\n",
    "    job_load=page.findChild(\"h3\", class_=\"page-subtitle\").find_next(\"li\").get_text()\n",
    "    responsibilities=page.find(\"div\", id=\"jmfe-custom-job_responsibilities\").get_text()\n",
    "    qualifications=page.find(\"div\", id=\"jmfe-custom-job_required_qualifications\").get_text() \n",
    "    return company_name,position,location,category,job_load,responsibilities,qualifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2>3.Crawling, getting and saving the data into csv</h2> <a name=\"crawl\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crawling ijob.am and saving the data into final_data_ijob list\n",
    "# continue is for going to next iteration regardless of the exceptions raised by the code\n",
    "final_data_ijob=[]\n",
    "for i in  job_desc_urls:\n",
    "    try:\n",
    "        all_data=get_all(i)\n",
    "    except:\n",
    "        continue\n",
    "    final_data_ijob.append(all_data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving in dataframe and csv file\n",
    "pd.DataFrame(pd.DataFrame(final_data_ijob,columns=[\"company_name\",\"position\",\"location\",\"category\",\"job_load\",\"responsibilities\",\"qualifications\"])).to_csv(\"Final_data_ijob.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
